## 1.线性回归(Linear Regression)

### 1.1什么是线性回归

我们首先用弄清楚什么是线性，什么是非线性。

- 线性：两个变量之间的关系**是**一次函数关系的——图象**是直线**，叫做线性。

  **注意：题目的线性是指广义的线性，也就是数据与数据之间的关系。**

- 非线性：两个变量之间的关系**不是**一次函数关系的——图象**不是直线**，叫做非线性。


相信通过以上两个概念大家已经很清楚了，其次我们经常说的回归回归到底是什么意思呢。

- 回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算**回归到真实值**，这就是回归的由来。

通俗的说就是用一个函数去逼近这个真实值，那又有人问了，线性回归不是用来做预测吗？是的，通过大量的数据我们是可以预测到**真实值**的。如果还是不明白，大家可以加一下我的**微信：wei15693176** 进行讨论。

### 1.2线性回归要解决什么问题

对大量的观测数据进行处理，从而得到比较符合事物内部规律的数学表达式。也就是说寻找到数据与数据之间的规律所在，从而就可以模拟出结果，也就是对结果进行预测。解决的就是通过已知的数据得到未知的结果。例如：对房价的预测、判断信用评价、电影票房预估等。

### 1.3线性回归的一般模型

![image.png](https://upload-images.jianshu.io/upload_images/13876065-b927c20ab2bf4ae6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

大家看上面图片，图片上有很多个小点点，通过这些小点点我们很难预测当x值=某个值时，y的值是多少，我们无法得知，所以，数学家是很聪明的，是否能够找到一条直线来描述这些点的趋势或者分布呢？答案是肯定的。相信大家在学校的时候都学过这样的直线，只是当时不知道这个方程在现实中是可以用来预测很多事物的。

那么问题来了，什么是模型呢？先来看看下面这幅图。

![image.png](https://upload-images.jianshu.io/upload_images/13876065-1fbb9e5eec9ecb8e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

假设数据就是**x**，结果是**y**，那中间的模型其实就是一个**方程**，这是一种片面的解释，但有助于我们去理解模型到底是个什么东西。以前在学校的时候总是不理解数学建模比赛到底在做些什么，现在理解了，是从题目给的数据中找到数据与数据之间的关系，建立数学方程模型，得到结果解决现实问题。其实是和机器学习中的模型是一样的意思。那么线性回归的一般模型是什么呢？

![image.png](https://upload-images.jianshu.io/upload_images/13876065-0c9ebd2624606014.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

模型神秘的面纱已经被我们揭开了，就是以上这个公式，不要被公式吓到，只要知道模型长什么样就行了。假设i=0，表示的是一元一次方程，是穿过坐标系中原点的一条直线，以此类推。

### 1.4如何使用模型

我们知道x是已知条件，通过公式求出y。已知条件其实就是我们的数据，以预测房价的案例来说明：

![image.png](https://upload-images.jianshu.io/upload_images/13876065-c4f9fd8b9abfe1ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图给出的是某个地区房价的一些相关信息，有日期、房间数、建筑面积、房屋评分等特征，表里头的数据就是我们要的x1、x2、x3…….... 自然的表中的price列就是房屋的价格，也就是y。现在需要求的就是theta的值了，后续步骤都需要依赖计算机来训练求解。

### 1.5模型计算

当然，这些计算虽然复杂，但python库中有现成的函数直接调用就可以求解。我们为了理解内部的计算原理，就需要一步一步的来剖析计算过程。

为了容易理解模型，假设该模型是一元一次函数，我们把一组数据x和y带入模型中，会得到如下图所示线段。

![image.png](https://upload-images.jianshu.io/upload_images/13876065-ff1fd5e2ac8b5cb0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

是不是觉得这条直线拟合得不够好？显然最好的效果应该是这条直线穿过所有的点才是，需要对模型进行优化，这里我们要引入一个概念。

- **损失函数**：是用来估量你模型的预测值 f(x)与真实值 YY 的不一致程度，损失函数越小，模型的效果就越好。

![image-20181209191632406](/Users/match/Library/Application Support/typora-user-images/image-20181209191632406.png)

不要看公式很复杂，其实就是一句话，(预测值-真实值)的平法和的平均值，换句话说就是点到直线距离和最小。用一幅图来表示：

![image.png](https://upload-images.jianshu.io/upload_images/13876065-8f682f5247227b19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**解释**：一开始损失函数是比较大的，但随着直线的不断变化(模型不断训练)，损失函数会越来越小，从而达到极小值点，也就是我们要得到的最终模型。

这种方法我们统称为**梯度下降法**。随着模型的不断训练，损失函数的梯度越来越平，直至极小值点，点到直线的距离和最小，所以这条直线就会经过所有的点，这就是我们要求的模型(函数)。

以此类推，高维的线性回归模型也是一样的，利用梯度下降法优化模型，寻找极值点，这就是模型训练的过程。
